{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Strands Agents SDK と Claude 4 インタリーブドシンキングによるツールとしてのエージェント\n",
    "\n",
    "このノートブックでは、Strands Agents SDK と Claude 4 の**インタリーブドシンキング**機能を使い、専門エージェントを連携させたインテリジェントなワークフローの構築方法を紹介します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## インタリーブドシンキングとは\n",
    "\n",
    "### インタリーブドシンキングとは？\n",
    "\n",
    "インタリーブドシンキングは、Claude 4 モデルに搭載された新機能で、モデルが以下のことを可能にします：\n",
    "\n",
    "1. **ツール呼び出しの合間に思考**：結果を処理・推論し、次のステップを決定\n",
    "2. **複数ツールを推論しながら連鎖的に利用**：高度なマルチステップ意思決定が可能\n",
    "3. **中間結果に応じて戦略を動的に適応**\n",
    "\n",
    "### 仕組み\n",
    "\n",
    "従来のエージェントのイベントループとインタリーブドシンキングのイベントループには多くの共通点があります：\n",
    "\n",
    "```\n",
    "\n",
    "クエリ → LLMが思考 → LLMがツール呼び出しを決定 → イベントループがツールを実行 → 出力がLLMに返る → [LLMがツール呼び出し不要または最終回答を出すまで繰り返し]\n",
    "\n",
    "```\n",
    "\n",
    "主な違いは、インタリーブドシンキングではイベントループがLLMの「思考」に基づいて動作する点です。従来はLLMの思考は隠されており、ツール呼び出しや最終回答が出るまで待つ必要がありました。\n",
    "\n",
    "インタリーブドシンキングでは、LLMが「思考」している間にその内容がイベントループに「漏れ出し」、LLMが思考した時点でツールが即座に実行されます。つまり、LLMが最初の「決定」を下す時点で、すでに最終回答が得られていることが多いのです。\n",
    "\n",
    "### 有効化方法\n",
    "\n",
    "StrandsとBedrockでこの機能を有効化するには：\n",
    "- `temperature=1` を設定（thinking有効時は必須）\n",
    "- ベータヘッダー追加: `\"anthropic_beta\": [\"interleaved-thinking-2025-05-14\"]`\n",
    "- 推論バジェット設定: `\"reasoning_config\": {\"type\": \"enabled\", \"budget_tokens\": 3000}`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## セットアップとインポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from strands import Agent, tool\n",
    "from strands.models import BedrockModel\n",
    "from strands.models import bedrock\n",
    "\n",
    "bedrock.DEFAULT_BEDROCK_MODEL_ID = \"us.anthropic.claude-3-7-sonnet-20250219-v1:0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 専門エージェント（ツール）の定義\n",
    "\n",
    "まず、Strands の `@tool` デコレータを使って4つの専門エージェントを作成します：\n",
    "\n",
    "- **リサーチャー**：事実情報の収集\n",
    "- **データアナリスト**：情報の分析・処理\n",
    "- **ファクトチェッカー**：情報の正確性検証\n",
    "- **レポートライター**：最終レポートの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specialist agents implemented as tools using Strands @tool decorator\n",
    "@tool\n",
    "def researcher(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Research specialist that gathers factual information.\n",
    "    \n",
    "    Args:\n",
    "        query: Research question or topic to investigate\n",
    "        \n",
    "    Returns:\n",
    "        Research findings and sources\n",
    "    \"\"\"\n",
    "    # Create a focused research agent\n",
    "    # Note: Each call creates a fresh agent instance (stateless)\n",
    "    research_agent = Agent(\n",
    "        model=\"us.anthropic.claude-3-7-sonnet-20250219-v1:0\",  # Optional: Specify the model ID\n",
    "        system_prompt=\"You are a research specialist. Gather factual information and cite sources when possible. Keep responses under 200 words.\",\n",
    "        callback_handler=None  # No streaming for tool agents\n",
    "    )\n",
    "    \n",
    "    # Execute the research task\n",
    "    result = research_agent(f\"Research: {query}\")\n",
    "    return str(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def data_analyst(data: str) -> str:\n",
    "    \"\"\"\n",
    "    Data analyst that processes and analyzes information.\n",
    "    \n",
    "    Args:\n",
    "        data: Raw data or research findings to analyze\n",
    "        \n",
    "    Returns:\n",
    "        Analysis with insights and patterns\n",
    "    \"\"\"\n",
    "    # Analyst agent focuses on extracting insights\n",
    "    analysis_agent = Agent(\n",
    "        model=\"us.anthropic.claude-3-7-sonnet-20250219-v1:0\",\n",
    "        system_prompt=\"You are a data analyst. Extract key insights, identify patterns, and provide analytical conclusions. Focus on actionable insights.\",\n",
    "        callback_handler=None\n",
    "    )\n",
    "    \n",
    "    # Analyze the provided data\n",
    "    result = analysis_agent(f\"Analyze this data and provide insights: {data}\")\n",
    "    return str(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def fact_checker(information: str) -> str:\n",
    "    \"\"\"\n",
    "    Fact checker that verifies information accuracy.\n",
    "    \n",
    "    Args:\n",
    "        information: Claims or data to verify\n",
    "        \n",
    "    Returns:\n",
    "        Fact-check results with accuracy assessment\n",
    "    \"\"\"\n",
    "    # Fact-checking agent for verification\n",
    "    fact_check_agent = Agent(\n",
    "        model=\"us.anthropic.claude-3-7-sonnet-20250219-v1:0\",\n",
    "        system_prompt=\"You are a fact checker. Verify claims, assess credibility, and provide confidence levels. Identify any questionable statements.\",\n",
    "        callback_handler=None\n",
    "    )\n",
    "    \n",
    "    # Verify the information\n",
    "    result = fact_check_agent(f\"Fact-check this information: {information}\")\n",
    "    return str(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def report_writer(analysis: str) -> str:\n",
    "    \"\"\"\n",
    "    Report writer that creates polished final documents.\n",
    "    \n",
    "    Args:\n",
    "        analysis: Analyzed data and insights\n",
    "        \n",
    "    Returns:\n",
    "        Formatted final report\n",
    "    \"\"\"\n",
    "    # Writer agent for professional output\n",
    "    writer_agent = Agent(\n",
    "        system_prompt=\"You are a professional report writer. Create clear, well-structured reports with executive summaries and actionable recommendations.\",\n",
    "        callback_handler=None\n",
    "    )\n",
    "    \n",
    "    # Create the report\n",
    "    result = writer_agent(f\"Create a professional report based on: {analysis}\")\n",
    "    return str(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Claude 4 オーケストレーター（インタリーブドシンキング対応）\n",
    "\n",
    "次に、インタリーブドシンキングを活用して専門エージェントを知的に連携させるClaude 4オーケストレーターを作成します。\n",
    "\n",
    "### オーケストレーターの動作概要：\n",
    "\n",
    "1. ユーザーから高レベルなタスクを受け取る\n",
    "2. **必要な情報を思考**\n",
    "3. researcherツールで初期データを収集\n",
    "4. **リサーチ結果を思考し、必要な分析を考える**\n",
    "5. data analystで分析\n",
    "6. **正確性や検証の必要性を思考**\n",
    "7. 必要に応じてfact checkerを呼び出す\n",
    "8. **結果の提示方法を思考**\n",
    "9. report writerで最終出力を作成\n",
    "10. **全体のワークフローを振り返り、最終回答を返す**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Claude 4 Orchestrator with Interleaved Thinking using Strands\n",
    "class StrandsInterlevedWorkflowOrchestrator:\n",
    "    def __init__(self):\n",
    "        # Define the orchestrator system prompt for intelligent workflow coordination\n",
    "        self.system_prompt = \"\"\"You are an intelligent workflow orchestrator with access to specialist agents.\n",
    "\n",
    "        Your role is to intelligently coordinate a workflow using these specialist agents:\n",
    "        - researcher: Gathers factual information on any topic\n",
    "        - data_analyst: Analyzes data and extracts insights\n",
    "        - fact_checker: Verifies accuracy of information  \n",
    "        - report_writer: Creates polished final reports\n",
    "\n",
    "        \"\"\"\n",
    "    \n",
    "    def run_workflow(self, task: str, enable_interleaved_thinking: bool = True) -> str:\n",
    "        \"\"\"Execute an intelligent workflow for the given task.\n",
    "        \n",
    "        Args:\n",
    "            task: The task to complete\n",
    "            enable_interleaved_thinking: Whether to enable interleaved thinking (default: True)\n",
    "        \n",
    "        The orchestrator will:\n",
    "        1. Understand the task requirements\n",
    "        2. Think about the best approach\n",
    "        3. Coordinate specialist agents\n",
    "        4. Reflect on results between steps\n",
    "        5. Produce a comprehensive output\n",
    "        \"\"\"\n",
    "        thinking_mode = \"WITH interleaved thinking\" if enable_interleaved_thinking else \"WITHOUT interleaved thinking\"\n",
    "        print(f\"\\nStarting intelligent workflow {thinking_mode} for: {task}\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        # Configure Claude 4 with or without interleaved thinking via Bedrock\n",
    "        if enable_interleaved_thinking:\n",
    "            claude4_model = BedrockModel(\n",
    "                model_id=\"us.anthropic.claude-sonnet-4-20250514-v1:0\",\n",
    "                max_tokens=4096,\n",
    "                temperature=1,  # Required to be 1 when thinking is enabled\n",
    "                additional_request_fields={\n",
    "                    # Enable interleaved thinking beta feature\n",
    "                    \"anthropic_beta\": [\"interleaved-thinking-2025-05-14\"],\n",
    "                    # Configure reasoning parameters\n",
    "                    \"reasoning_config\": {\n",
    "                        \"type\": \"enabled\",  # Turn on thinking\n",
    "                        \"budget_tokens\": 3000  # Thinking token budget\n",
    "                    }\n",
    "                }\n",
    "            )\n",
    "        else:\n",
    "            claude4_model = BedrockModel(\n",
    "                model_id=\"us.anthropic.claude-sonnet-4-20250514-v1:0\",\n",
    "                max_tokens=4096,\n",
    "                temperature=1\n",
    "            )\n",
    "        \n",
    "        # Create the orchestrator agent with Claude 4 and specialist tools\n",
    "        orchestrator = Agent(\n",
    "            model=claude4_model,\n",
    "            system_prompt=self.system_prompt,\n",
    "            tools=[researcher, data_analyst, fact_checker, report_writer]\n",
    "        )\n",
    "        \n",
    "        prompt = f\"\"\"Complete this task using intelligent workflow coordination: {task}\n",
    "\n",
    "        Instructions:\n",
    "        1. Think carefully about what information you need to accomplish this task\n",
    "        2. Use the specialist agents strategically - each has unique strengths\n",
    "        3. After each tool use, reflect on the results and adapt your approach\n",
    "        4. Coordinate multiple agents as needed for comprehensive results\n",
    "        5. Ensure accuracy by fact-checking when appropriate\n",
    "        6. Provide a comprehensive final response that addresses all aspects\n",
    "        \n",
    "        Remember: Your thinking between tool calls helps you make better decisions.\n",
    "        Use it to plan, evaluate results, and adjust your strategy.\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            result = orchestrator(prompt)\n",
    "            return str(result)\n",
    "        except Exception as e:\n",
    "            return f\"Workflow failed: {e}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## デモ実行\n",
    "\n",
    "オーケストレーターの動作を実際に見てみましょう！思考しながらツールを呼び出す様子に注目してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the orchestrator\n",
    "print(\"Strands Agents SDK: Claude 4 Interleaved Thinking Workflow Demo\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "try:\n",
    "    orchestrator = StrandsInterlevedWorkflowOrchestrator()\n",
    "    print(\"✅ Orchestrator initialized successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Failed to initialize orchestrator: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the workflow with a test case\n",
    "test_case = \"Analyze the impact of remote work on productivity and provide strategic recommendations\"\n",
    "\n",
    "print(f\"📋 Task: {test_case}\\n\")\n",
    "\n",
    "try:\n",
    "    result = orchestrator.run_workflow(test_case)\n",
    "    \n",
    "    print(f\"\\n📊 Workflow Result:\")\n",
    "    print(\"=\" * 70)\n",
    "    print(result)\n",
    "except Exception as e:\n",
    "    print(f\"❌ Workflow execution failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## インタリーブドシンキングなしで試す\n",
    "\n",
    "オーケストレーターをインタリーブドシンキング無効で実行し、出力の違いを観察してみましょう。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's try the same task WITHOUT interleaved thinking\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"🔄 Now running the same task WITHOUT interleaved thinking\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "try:\n",
    "    result_without_thinking = orchestrator.run_workflow(test_case, enable_interleaved_thinking=False)\n",
    "    \n",
    "    print(f\"\\n📊 Workflow Result (Without Interleaved Thinking):\")\n",
    "    print(\"=\" * 70)\n",
    "    print(result_without_thinking)\n",
    "except Exception as e:\n",
    "    print(f\"❌ Workflow execution failed: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".inter-strands",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
