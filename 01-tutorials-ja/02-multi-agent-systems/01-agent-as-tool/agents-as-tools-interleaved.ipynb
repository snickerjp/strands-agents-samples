{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Strands Agents SDK ã¨ Claude 4 ã‚¤ãƒ³ã‚¿ãƒªãƒ¼ãƒ–ãƒ‰ã‚·ãƒ³ã‚­ãƒ³ã‚°ã«ã‚ˆã‚‹ãƒ„ãƒ¼ãƒ«ã¨ã—ã¦ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆ\n",
    "\n",
    "ã“ã®ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã§ã¯ã€Strands Agents SDK ã¨ Claude 4 ã®**ã‚¤ãƒ³ã‚¿ãƒªãƒ¼ãƒ–ãƒ‰ã‚·ãƒ³ã‚­ãƒ³ã‚°**æ©Ÿèƒ½ã‚’ä½¿ã„ã€å°‚é–€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’é€£æºã•ã›ãŸã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ãƒˆãªãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã®æ§‹ç¯‰æ–¹æ³•ã‚’ç´¹ä»‹ã—ã¾ã™ã€‚"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ã‚¤ãƒ³ã‚¿ãƒªãƒ¼ãƒ–ãƒ‰ã‚·ãƒ³ã‚­ãƒ³ã‚°ã¨ã¯\n",
    "\n",
    "### ã‚¤ãƒ³ã‚¿ãƒªãƒ¼ãƒ–ãƒ‰ã‚·ãƒ³ã‚­ãƒ³ã‚°ã¨ã¯ï¼Ÿ\n",
    "\n",
    "ã‚¤ãƒ³ã‚¿ãƒªãƒ¼ãƒ–ãƒ‰ã‚·ãƒ³ã‚­ãƒ³ã‚°ã¯ã€Claude 4 ãƒ¢ãƒ‡ãƒ«ã«æ­è¼‰ã•ã‚ŒãŸæ–°æ©Ÿèƒ½ã§ã€ãƒ¢ãƒ‡ãƒ«ãŒä»¥ä¸‹ã®ã“ã¨ã‚’å¯èƒ½ã«ã—ã¾ã™ï¼š\n",
    "\n",
    "1. **ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ã®åˆé–“ã«æ€è€ƒ**ï¼šçµæœã‚’å‡¦ç†ãƒ»æ¨è«–ã—ã€æ¬¡ã®ã‚¹ãƒ†ãƒƒãƒ—ã‚’æ±ºå®š\n",
    "2. **è¤‡æ•°ãƒ„ãƒ¼ãƒ«ã‚’æ¨è«–ã—ãªãŒã‚‰é€£é–çš„ã«åˆ©ç”¨**ï¼šé«˜åº¦ãªãƒãƒ«ãƒã‚¹ãƒ†ãƒƒãƒ—æ„æ€æ±ºå®šãŒå¯èƒ½\n",
    "3. **ä¸­é–“çµæœã«å¿œã˜ã¦æˆ¦ç•¥ã‚’å‹•çš„ã«é©å¿œ**\n",
    "\n",
    "### ä»•çµ„ã¿\n",
    "\n",
    "å¾“æ¥ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ã¨ã‚¤ãƒ³ã‚¿ãƒªãƒ¼ãƒ–ãƒ‰ã‚·ãƒ³ã‚­ãƒ³ã‚°ã®ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ã«ã¯å¤šãã®å…±é€šç‚¹ãŒã‚ã‚Šã¾ã™ï¼š\n",
    "\n",
    "```\n",
    "\n",
    "ã‚¯ã‚¨ãƒª â†’ LLMãŒæ€è€ƒ â†’ LLMãŒãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ã‚’æ±ºå®š â†’ ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ãŒãƒ„ãƒ¼ãƒ«ã‚’å®Ÿè¡Œ â†’ å‡ºåŠ›ãŒLLMã«è¿”ã‚‹ â†’ [LLMãŒãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ä¸è¦ã¾ãŸã¯æœ€çµ‚å›ç­”ã‚’å‡ºã™ã¾ã§ç¹°ã‚Šè¿”ã—]\n",
    "\n",
    "```\n",
    "\n",
    "ä¸»ãªé•ã„ã¯ã€ã‚¤ãƒ³ã‚¿ãƒªãƒ¼ãƒ–ãƒ‰ã‚·ãƒ³ã‚­ãƒ³ã‚°ã§ã¯ã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ãŒLLMã®ã€Œæ€è€ƒã€ã«åŸºã¥ã„ã¦å‹•ä½œã™ã‚‹ç‚¹ã§ã™ã€‚å¾“æ¥ã¯LLMã®æ€è€ƒã¯éš ã•ã‚Œã¦ãŠã‚Šã€ãƒ„ãƒ¼ãƒ«å‘¼ã³å‡ºã—ã‚„æœ€çµ‚å›ç­”ãŒå‡ºã‚‹ã¾ã§å¾…ã¤å¿…è¦ãŒã‚ã‚Šã¾ã—ãŸã€‚\n",
    "\n",
    "ã‚¤ãƒ³ã‚¿ãƒªãƒ¼ãƒ–ãƒ‰ã‚·ãƒ³ã‚­ãƒ³ã‚°ã§ã¯ã€LLMãŒã€Œæ€è€ƒã€ã—ã¦ã„ã‚‹é–“ã«ãã®å†…å®¹ãŒã‚¤ãƒ™ãƒ³ãƒˆãƒ«ãƒ¼ãƒ—ã«ã€Œæ¼ã‚Œå‡ºã—ã€ã€LLMãŒæ€è€ƒã—ãŸæ™‚ç‚¹ã§ãƒ„ãƒ¼ãƒ«ãŒå³åº§ã«å®Ÿè¡Œã•ã‚Œã¾ã™ã€‚ã¤ã¾ã‚Šã€LLMãŒæœ€åˆã®ã€Œæ±ºå®šã€ã‚’ä¸‹ã™æ™‚ç‚¹ã§ã€ã™ã§ã«æœ€çµ‚å›ç­”ãŒå¾—ã‚‰ã‚Œã¦ã„ã‚‹ã“ã¨ãŒå¤šã„ã®ã§ã™ã€‚\n",
    "\n",
    "### æœ‰åŠ¹åŒ–æ–¹æ³•\n",
    "\n",
    "Strandsã¨Bedrockã§ã“ã®æ©Ÿèƒ½ã‚’æœ‰åŠ¹åŒ–ã™ã‚‹ã«ã¯ï¼š\n",
    "- `temperature=1` ã‚’è¨­å®šï¼ˆthinkingæœ‰åŠ¹æ™‚ã¯å¿…é ˆï¼‰\n",
    "- ãƒ™ãƒ¼ã‚¿ãƒ˜ãƒƒãƒ€ãƒ¼è¿½åŠ : `\"anthropic_beta\": [\"interleaved-thinking-2025-05-14\"]`\n",
    "- æ¨è«–ãƒã‚¸ã‚§ãƒƒãƒˆè¨­å®š: `\"reasoning_config\": {\"type\": \"enabled\", \"budget_tokens\": 3000}`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ã¨ã‚¤ãƒ³ãƒãƒ¼ãƒˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from strands import Agent, tool\n",
    "from strands.models import BedrockModel\n",
    "from strands.models import bedrock\n",
    "\n",
    "bedrock.DEFAULT_BEDROCK_MODEL_ID = \"us.anthropic.claude-3-7-sonnet-20250219-v1:0\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## å°‚é–€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆï¼ˆãƒ„ãƒ¼ãƒ«ï¼‰ã®å®šç¾©\n",
    "\n",
    "ã¾ãšã€Strands ã® `@tool` ãƒ‡ã‚³ãƒ¬ãƒ¼ã‚¿ã‚’ä½¿ã£ã¦4ã¤ã®å°‚é–€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’ä½œæˆã—ã¾ã™ï¼š\n",
    "\n",
    "- **ãƒªã‚µãƒ¼ãƒãƒ£ãƒ¼**ï¼šäº‹å®Ÿæƒ…å ±ã®åé›†\n",
    "- **ãƒ‡ãƒ¼ã‚¿ã‚¢ãƒŠãƒªã‚¹ãƒˆ**ï¼šæƒ…å ±ã®åˆ†æãƒ»å‡¦ç†\n",
    "- **ãƒ•ã‚¡ã‚¯ãƒˆãƒã‚§ãƒƒã‚«ãƒ¼**ï¼šæƒ…å ±ã®æ­£ç¢ºæ€§æ¤œè¨¼\n",
    "- **ãƒ¬ãƒãƒ¼ãƒˆãƒ©ã‚¤ã‚¿ãƒ¼**ï¼šæœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆã®ä½œæˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specialist agents implemented as tools using Strands @tool decorator\n",
    "@tool\n",
    "def researcher(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Research specialist that gathers factual information.\n",
    "    \n",
    "    Args:\n",
    "        query: Research question or topic to investigate\n",
    "        \n",
    "    Returns:\n",
    "        Research findings and sources\n",
    "    \"\"\"\n",
    "    # Create a focused research agent\n",
    "    # Note: Each call creates a fresh agent instance (stateless)\n",
    "    research_agent = Agent(\n",
    "        model=\"us.anthropic.claude-3-7-sonnet-20250219-v1:0\",  # Optional: Specify the model ID\n",
    "        system_prompt=\"You are a research specialist. Gather factual information and cite sources when possible. Keep responses under 200 words.\",\n",
    "        callback_handler=None  # No streaming for tool agents\n",
    "    )\n",
    "    \n",
    "    # Execute the research task\n",
    "    result = research_agent(f\"Research: {query}\")\n",
    "    return str(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def data_analyst(data: str) -> str:\n",
    "    \"\"\"\n",
    "    Data analyst that processes and analyzes information.\n",
    "    \n",
    "    Args:\n",
    "        data: Raw data or research findings to analyze\n",
    "        \n",
    "    Returns:\n",
    "        Analysis with insights and patterns\n",
    "    \"\"\"\n",
    "    # Analyst agent focuses on extracting insights\n",
    "    analysis_agent = Agent(\n",
    "        model=\"us.anthropic.claude-3-7-sonnet-20250219-v1:0\",\n",
    "        system_prompt=\"You are a data analyst. Extract key insights, identify patterns, and provide analytical conclusions. Focus on actionable insights.\",\n",
    "        callback_handler=None\n",
    "    )\n",
    "    \n",
    "    # Analyze the provided data\n",
    "    result = analysis_agent(f\"Analyze this data and provide insights: {data}\")\n",
    "    return str(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def fact_checker(information: str) -> str:\n",
    "    \"\"\"\n",
    "    Fact checker that verifies information accuracy.\n",
    "    \n",
    "    Args:\n",
    "        information: Claims or data to verify\n",
    "        \n",
    "    Returns:\n",
    "        Fact-check results with accuracy assessment\n",
    "    \"\"\"\n",
    "    # Fact-checking agent for verification\n",
    "    fact_check_agent = Agent(\n",
    "        model=\"us.anthropic.claude-3-7-sonnet-20250219-v1:0\",\n",
    "        system_prompt=\"You are a fact checker. Verify claims, assess credibility, and provide confidence levels. Identify any questionable statements.\",\n",
    "        callback_handler=None\n",
    "    )\n",
    "    \n",
    "    # Verify the information\n",
    "    result = fact_check_agent(f\"Fact-check this information: {information}\")\n",
    "    return str(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def report_writer(analysis: str) -> str:\n",
    "    \"\"\"\n",
    "    Report writer that creates polished final documents.\n",
    "    \n",
    "    Args:\n",
    "        analysis: Analyzed data and insights\n",
    "        \n",
    "    Returns:\n",
    "        Formatted final report\n",
    "    \"\"\"\n",
    "    # Writer agent for professional output\n",
    "    writer_agent = Agent(\n",
    "        system_prompt=\"You are a professional report writer. Create clear, well-structured reports with executive summaries and actionable recommendations.\",\n",
    "        callback_handler=None\n",
    "    )\n",
    "    \n",
    "    # Create the report\n",
    "    result = writer_agent(f\"Create a professional report based on: {analysis}\")\n",
    "    return str(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Claude 4 ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼ï¼ˆã‚¤ãƒ³ã‚¿ãƒªãƒ¼ãƒ–ãƒ‰ã‚·ãƒ³ã‚­ãƒ³ã‚°å¯¾å¿œï¼‰\n",
    "\n",
    "æ¬¡ã«ã€ã‚¤ãƒ³ã‚¿ãƒªãƒ¼ãƒ–ãƒ‰ã‚·ãƒ³ã‚­ãƒ³ã‚°ã‚’æ´»ç”¨ã—ã¦å°‚é–€ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã‚’çŸ¥çš„ã«é€£æºã•ã›ã‚‹Claude 4ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼ã‚’ä½œæˆã—ã¾ã™ã€‚\n",
    "\n",
    "### ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼ã®å‹•ä½œæ¦‚è¦ï¼š\n",
    "\n",
    "1. ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰é«˜ãƒ¬ãƒ™ãƒ«ãªã‚¿ã‚¹ã‚¯ã‚’å—ã‘å–ã‚‹\n",
    "2. **å¿…è¦ãªæƒ…å ±ã‚’æ€è€ƒ**\n",
    "3. researcherãƒ„ãƒ¼ãƒ«ã§åˆæœŸãƒ‡ãƒ¼ã‚¿ã‚’åé›†\n",
    "4. **ãƒªã‚µãƒ¼ãƒçµæœã‚’æ€è€ƒã—ã€å¿…è¦ãªåˆ†æã‚’è€ƒãˆã‚‹**\n",
    "5. data analystã§åˆ†æ\n",
    "6. **æ­£ç¢ºæ€§ã‚„æ¤œè¨¼ã®å¿…è¦æ€§ã‚’æ€è€ƒ**\n",
    "7. å¿…è¦ã«å¿œã˜ã¦fact checkerã‚’å‘¼ã³å‡ºã™\n",
    "8. **çµæœã®æç¤ºæ–¹æ³•ã‚’æ€è€ƒ**\n",
    "9. report writerã§æœ€çµ‚å‡ºåŠ›ã‚’ä½œæˆ\n",
    "10. **å…¨ä½“ã®ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‚’æŒ¯ã‚Šè¿”ã‚Šã€æœ€çµ‚å›ç­”ã‚’è¿”ã™**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Claude 4 Orchestrator with Interleaved Thinking using Strands\n",
    "class StrandsInterlevedWorkflowOrchestrator:\n",
    "    def __init__(self):\n",
    "        # Define the orchestrator system prompt for intelligent workflow coordination\n",
    "        self.system_prompt = \"\"\"You are an intelligent workflow orchestrator with access to specialist agents.\n",
    "\n",
    "        Your role is to intelligently coordinate a workflow using these specialist agents:\n",
    "        - researcher: Gathers factual information on any topic\n",
    "        - data_analyst: Analyzes data and extracts insights\n",
    "        - fact_checker: Verifies accuracy of information  \n",
    "        - report_writer: Creates polished final reports\n",
    "\n",
    "        \"\"\"\n",
    "    \n",
    "    def run_workflow(self, task: str, enable_interleaved_thinking: bool = True) -> str:\n",
    "        \"\"\"Execute an intelligent workflow for the given task.\n",
    "        \n",
    "        Args:\n",
    "            task: The task to complete\n",
    "            enable_interleaved_thinking: Whether to enable interleaved thinking (default: True)\n",
    "        \n",
    "        The orchestrator will:\n",
    "        1. Understand the task requirements\n",
    "        2. Think about the best approach\n",
    "        3. Coordinate specialist agents\n",
    "        4. Reflect on results between steps\n",
    "        5. Produce a comprehensive output\n",
    "        \"\"\"\n",
    "        thinking_mode = \"WITH interleaved thinking\" if enable_interleaved_thinking else \"WITHOUT interleaved thinking\"\n",
    "        print(f\"\\nStarting intelligent workflow {thinking_mode} for: {task}\")\n",
    "        print(\"=\" * 70)\n",
    "        \n",
    "        # Configure Claude 4 with or without interleaved thinking via Bedrock\n",
    "        if enable_interleaved_thinking:\n",
    "            claude4_model = BedrockModel(\n",
    "                model_id=\"us.anthropic.claude-sonnet-4-20250514-v1:0\",\n",
    "                max_tokens=4096,\n",
    "                temperature=1,  # Required to be 1 when thinking is enabled\n",
    "                additional_request_fields={\n",
    "                    # Enable interleaved thinking beta feature\n",
    "                    \"anthropic_beta\": [\"interleaved-thinking-2025-05-14\"],\n",
    "                    # Configure reasoning parameters\n",
    "                    \"reasoning_config\": {\n",
    "                        \"type\": \"enabled\",  # Turn on thinking\n",
    "                        \"budget_tokens\": 3000  # Thinking token budget\n",
    "                    }\n",
    "                }\n",
    "            )\n",
    "        else:\n",
    "            claude4_model = BedrockModel(\n",
    "                model_id=\"us.anthropic.claude-sonnet-4-20250514-v1:0\",\n",
    "                max_tokens=4096,\n",
    "                temperature=1\n",
    "            )\n",
    "        \n",
    "        # Create the orchestrator agent with Claude 4 and specialist tools\n",
    "        orchestrator = Agent(\n",
    "            model=claude4_model,\n",
    "            system_prompt=self.system_prompt,\n",
    "            tools=[researcher, data_analyst, fact_checker, report_writer]\n",
    "        )\n",
    "        \n",
    "        prompt = f\"\"\"Complete this task using intelligent workflow coordination: {task}\n",
    "\n",
    "        Instructions:\n",
    "        1. Think carefully about what information you need to accomplish this task\n",
    "        2. Use the specialist agents strategically - each has unique strengths\n",
    "        3. After each tool use, reflect on the results and adapt your approach\n",
    "        4. Coordinate multiple agents as needed for comprehensive results\n",
    "        5. Ensure accuracy by fact-checking when appropriate\n",
    "        6. Provide a comprehensive final response that addresses all aspects\n",
    "        \n",
    "        Remember: Your thinking between tool calls helps you make better decisions.\n",
    "        Use it to plan, evaluate results, and adjust your strategy.\n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            result = orchestrator(prompt)\n",
    "            return str(result)\n",
    "        except Exception as e:\n",
    "            return f\"Workflow failed: {e}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ãƒ‡ãƒ¢å®Ÿè¡Œ\n",
    "\n",
    "ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼ã®å‹•ä½œã‚’å®Ÿéš›ã«è¦‹ã¦ã¿ã¾ã—ã‚‡ã†ï¼æ€è€ƒã—ãªãŒã‚‰ãƒ„ãƒ¼ãƒ«ã‚’å‘¼ã³å‡ºã™æ§˜å­ã«æ³¨ç›®ã—ã¦ãã ã•ã„ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the orchestrator\n",
    "print(\"Strands Agents SDK: Claude 4 Interleaved Thinking Workflow Demo\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "try:\n",
    "    orchestrator = StrandsInterlevedWorkflowOrchestrator()\n",
    "    print(\"âœ… Orchestrator initialized successfully!\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Failed to initialize orchestrator: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the workflow with a test case\n",
    "test_case = \"Analyze the impact of remote work on productivity and provide strategic recommendations\"\n",
    "\n",
    "print(f\"ğŸ“‹ Task: {test_case}\\n\")\n",
    "\n",
    "try:\n",
    "    result = orchestrator.run_workflow(test_case)\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Workflow Result:\")\n",
    "    print(\"=\" * 70)\n",
    "    print(result)\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Workflow execution failed: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ã‚¤ãƒ³ã‚¿ãƒªãƒ¼ãƒ–ãƒ‰ã‚·ãƒ³ã‚­ãƒ³ã‚°ãªã—ã§è©¦ã™\n",
    "\n",
    "ã‚ªãƒ¼ã‚±ã‚¹ãƒˆãƒ¬ãƒ¼ã‚¿ãƒ¼ã‚’ã‚¤ãƒ³ã‚¿ãƒªãƒ¼ãƒ–ãƒ‰ã‚·ãƒ³ã‚­ãƒ³ã‚°ç„¡åŠ¹ã§å®Ÿè¡Œã—ã€å‡ºåŠ›ã®é•ã„ã‚’è¦³å¯Ÿã—ã¦ã¿ã¾ã—ã‚‡ã†ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now let's try the same task WITHOUT interleaved thinking\n",
    "print(\"\\n\" + \"=\"*70)\n",
    "print(\"ğŸ”„ Now running the same task WITHOUT interleaved thinking\")\n",
    "print(\"=\"*70)\n",
    "\n",
    "try:\n",
    "    result_without_thinking = orchestrator.run_workflow(test_case, enable_interleaved_thinking=False)\n",
    "    \n",
    "    print(f\"\\nğŸ“Š Workflow Result (Without Interleaved Thinking):\")\n",
    "    print(\"=\" * 70)\n",
    "    print(result_without_thinking)\n",
    "except Exception as e:\n",
    "    print(f\"âŒ Workflow execution failed: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".inter-strands",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
